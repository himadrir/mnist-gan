# -*- coding: utf-8 -*-
"""VanilaGAN_MNIST

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U_gpbW4JvfS3CDSVrL69qLWMic1Rk8TA
"""
import os
from time import time
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout
from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.layers import UpSampling2D, Conv2D

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import initializers
import tensorflow as tf

import matplotlib.pyplot as plt
import numpy as np
path = "C:/Users/himad/Documents/ML Projects/GAN/"



randomDim = 10
(x_train, y_train),(x_test, y_test) = mnist.load_data()

x_train = (x_train.astype(np.float32) - 127.5)/127.5

x_train = x_train.reshape(60000, 784)

adam = Adam(lr = 0.0002, beta_1=0.5)

generator = Sequential()
generator.add(Dense(256, input_dim=randomDim))
generator.add(LeakyReLU(0.2))
generator.add(Dense(512))
generator.add(LeakyReLU(0.2))
generator.add(Dense(1024))
generator.add(LeakyReLU(0.2))
generator.add(Dense(784, activation='tanh'))

discriminator = Sequential()
discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))
discriminator.add(Dropout(0.3))
discriminator.add(Dense(512))
discriminator.add(LeakyReLU(0.2))
discriminator.add(Dropout(0.3))
discriminator.add(LeakyReLU(0.2))
discriminator.add(Dropout(0.3))
discriminator.add(Dense(1, activation='sigmoid'))
discriminator.compile(loss='binary_crossentropy', optimizer=adam)

discriminator.trainable = False
ganInput = Input(shape=(randomDim,))
x = generator(ganInput)
ganOutput = discriminator(x)

gan = Model(inputs=ganInput, outputs=ganOutput)
gan.compile(loss='binary_crossentropy', optimizer=adam)

dLosses = []
gLosses = []

def plotLoss(epoch):
  plt.figure(figsize=(10, 8))
  plt.plot(dLosses, label='Discriminitive loss')
  plt.plot(gLosses, label='Generative loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.legend()
  plt.savefig(path+'outputs/gan_loss_epoch_%d.png' % epoch)

def saveGeneratedImages(epoch, examples=100, dim=(10,10), figsize=(10,10)):
  noise = np.random.normal(0, 1, size=[examples, randomDim])
  generatedImages = generator.predict(noise)
  generatedImages = generatedImages.reshape(examples, 28, 28)
  plt.figure(figsize=figsize)
  for i in range(generatedImages.shape[0]):
    plt.subplot(dim[0], dim[1], i+1)
    plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')
    plt.axis('off')
  plt.tight_layout()
  plt.savefig(path+'images/gan_generated_image_epoch_%d.png'% epoch)

def train(epochs=1, batchSize=128):

  start = time()
  batch_train_time = 0
  dloss = 1
  gloss = 1
  batchCount = int(x_train.shape[0] / batchSize)
  print('Epochs: ', epochs)
  print('Batch size: ', batchSize)
  print('Batch per epoch: ', batchCount)

  for i in range(1, epochs+1):
    print('-'*15, 'Epoch %d' % i,'-'*15)
    batch_train_time = time()
    for _ in range(batchCount):
      noise = np.random.normal(0, 1, size=[batchSize, randomDim])
      imageBatch = x_train[np.random.randint(0, x_train.shape[0], size=batchSize)]
      generatedImages = generator.predict(noise)
      x = np.concatenate([imageBatch, generatedImages])
      # print(np.shape(imageBatch), np.shape(generatedImages))
      yDis = np.zeros(2*batchSize)
      yDis[:batchSize] = 0.9

      discriminator.trainable = True
      dloss = discriminator.train_on_batch(x, yDis)

      noise = np.random.normal(0, 1, size=[batchSize, randomDim])
      yGen = np.ones(batchSize)
      discriminator.trainable = False
      gloss = gan.train_on_batch(noise, yGen)


    dLosses.append(dloss)
    gLosses.append(gloss)
    
    print("Epoch: %d" % i)
    print("avg Discriminator Loss: %f" % np.mean(dloss))
    print("avg Generator Loss: %f" % np.mean(gloss))
    print("Batch training time: %f seconds\n" % (time()-batch_train_time))
    
    if i==1 or i%20 == 0:
       saveGeneratedImages(i)

  print("Total training time: %f seconds" % (time()-start))
  plotLoss(i)



train(100, 128)

discriminator.save(path+"models/discriminator.h5")
generator.save(path+"models/generator.h5")